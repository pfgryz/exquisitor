\clearpage 
\section{Eksperymenty}

    W ramach pracy przeprowadzono eksperymenty polegające na porównaniu wydajności oraz jakości zaimplementowanych metod do grupowania sekwencji genetycznych w kontekście pełnej klasyfikacji taksonomicznej. W eksperymentach jako punkt odniesienia wybrano klasyfikację taksonomiczną wszystkich sekwencji wejściowych z pominięciem etapów grupowania sekwencji genetycznych.

    % ===== ===== ===== =====
    % OPIS ŚRODOWISKA EKSPERYMENTALNEGO
    % ===== ===== ===== ===== 
    \subsection{Opis środowiska eksperymentalnego}

        Eksperymenty zostały przeprowadzone na maszynie wirtualnej wykorzystującej technologię KVM o specyfikacji podanej poniżej:

        \subsubsection{Specyfikacja techniczna}\

            \begin{itemize}
                \item {
                    \textbf{System operacyjny:} Ubuntu 22.04 LTS.
                }
                \item {
                    \textbf{Procesor:} 4 rdzenie wirtualne Intel Core i7-6850K.
                }
                \item {
                    \textbf{Pamięć RAM:} 40GB.
                }
                \item {
                    \textbf{Karta graficzna:} Nvidia GeForce GTX 1080 TI.
                }
                \item {
                    \textbf{Dysk:} dysk sieciowy 1 TB z prędkością odczytu 1 Gbps.
                }
                \item {
                    \textbf{Oprogramowanie:} pakiet \texttt{BLAST} w wersji 2.16.0 oraz sterowniki karty graficznej.
                }
            \end{itemize}

    % ===== ===== ===== =====
    % MIARA JAKOŚCI
    % ===== ===== ===== =====
    \subsection{Miara jakości}

        Jako miarę jakości klasyfikacji taksonomicznej wykorzystano indeks Jaccarda, wyrażony wzorem:

        \begin{equation}
            \text{Miara jakości} = \frac{\| R \cap E \|}{\| E \cup E \|}
        \end{equation}

        gdzie 
        \begin{align*}
            R &- \text{referencyjny zbiór organizmów,} \\
            E &- \text{zbiór organizmów otrzymanych.}
        \end{align*}

        Miara została wykorzystana do porównania jakości klasyfikacji taksonomicznej przeprowadzanej z wykorzystaniem zaimplementowanych metod względem klasyfikacji taksonomicznej bez użycia potoku przetwarzania.

        Wykorzystano również dodatkowe miary jakości, które zostały zastosowane do oceny jakości utworzonych grup przez potok przetwarzania. Pierwszą wykorzystaną miarą jest znormalizowana informacja wzajemna (ang. \textit{Normalized mutual information, NMI}) i służy do oceny jakości grup, drugą jest czułość (ang. \textit{sensitivity}), która wykorzystana jest do oceny reprezentantów grup. Miary zostały zdefiniowane odpowiednio wzorami:

        \begin{equation}
            NMI(X, Y) = \frac{I(X; Y)}{\sqrt{H(X) \cdot H(Y)}}
        \end{equation}

        gdzie,
        \begin{align*}
            I(X; Y) &= \sum_{y \in Y}{ \sum_{x \in X}{p(x, y) \log_{2}{\frac{p(x, y)}{p(x) p(y)}}}}, \\
            H(X) &= - \sum_{x \in X}{ p(x) \log_{2}{p(x)}}, \\
            I(X; Y) &- \text{informacja wzajemna między zbiorami $X$ oraz $Y$}, \\
            H(X) &- \text{entropia zbioru $X$}, \\
            H(Y) &- \text{entropia zbioru $Y$}, \\
            p(x) &- \text{prawdopobieństwo zajścia zdarzenia $x$}, \\
            p(x, y) &- \text{wspólny rozkład prawdopodobieństwa $X$ oraz $Y$ }.
        \end{align*}

        \begin{equation}
            sensitivity = \frac{\text{TP}}{
                \text{TP} + \text{TN}
            }
        \end{equation}

        gdzie,
        \begin{align*}
            TP &- \text{liczba wyników prawdziwie dodatnych,} \\
            TN &- \text{liczba wyników fałszywie ujemnych.}
        \end{align*}

        Dodatkowe miary jakości zostały wykorzystane do oceny jakości grup względem grupowania z wykorzystaniem zmodyfikowanego algorytmu Needlemana-Wunscha.

    % ===== ===== ===== =====
    % ZBIÓR DANYCH
    % ===== ===== ===== =====
    \subsection{Zbiór danych}

        \subsubsection{Opis zbioru danych}
        
            W eksperymentach wykorzystano ten sam zbiór sekwencji genetycznych, co w uczeniu modelu sztucznej sieci neuronowej. Zbiór \textit{CAMI II Toy Human Microbiome Project}\cite{Fritz2019} został wybrany, ponieważ został stworzony w celu oceny wydajności algorytmów bioinformatycznych oraz zawiera znaczną liczbę sekwencji genetycznych, co umożliwiło jego wykorzystanie go zarówno w eksperymentach, jak i w uczeniu modelu sztucznej sieci neuronowej.
            
            Na podstawie zbioru stworzono podzbiory sekwencji o rozmiarach wyrażonych wzorem $2^k$ dla $k \in [0, 15]$. Zbiory są rozłączne, a do ich budowy wykorzystano wyłącznie te sekwencje, które nie zostały użyte do uczenia modelu sztucznej sieci neuronowej.

        \subsubsection{Przygotowanie zbioru danych}

            Podzbiory powstały poprzez losowanie bez zwracania indeksów sekwencji genetycznych ze zbioru referencyjnego, które powinny trafić do podzbioru. W losowaniu wykorzystano informację o indeksach sekwencji wykorzystanych w zbiorze uczącym oraz walidacyjnym sztucznej sieci neuronowej. W celu umożliwienia dalszego wykorzystania zbioru danych zapisano do pliku indeksy sekwencji wykorzystanych w procesie budowy zbioru eksperymentalnego.

    % ===== ===== ===== =====
    % PROCEDURA PRZEPROWADZANIA EKSPERYMENTÓW
    % ===== ===== ===== =====
    \subsection{Procedura przeprowadzania eksperymentów}

        Eksperymenty zostały przeprowadzone za pomocą zaimplementowane polecenia aplikacji konsolowej, które pozwala na nadzorowanie wykorzystania procesora oraz pamięci RAM przez eksperyment, oraz kontrolowanie maksymalnego czasu trwania eksperymentu.

        Dane do obu eksperymentów zostały zgromadzone w wyniku przeprowadzenia klasyfikacji taksonomicznej z wykorzystaniem zaimplementowanych metod oraz klasyfikacji taksonomicznej bez wykorzystania potoku przetwarzania dla każdego podzbioru osobno.

        \subsubsection{Parametry}

            Maksymalny czas trwania jednej klasyfikacji taksonomicznej został ograniczony do 12 godzin. Dla wszystkich metod wybrano algorytm grupowania k-medoidów oraz określono liczbę tworzonych grup przez algorytm grupowania za pomocą wzoru $\sqrt{n}$, gdzie $n$ to liczba sekwencji wejściowych. W metodzie z wykorzystaniem zmodyfikowanego algorytmu Needlemana-Wunscha wykorzystano parametry określone w sekcji~\ref{Method:NeedlemaWunsch}. W przypadku metody wykorzystującej zanurzenia $k$-merów parametr $k$ został ustawiony na $4$. W metodzie z wykorzystaniem sztucznej sieci neuronowej wykorzystano wcześniej stworzony model.

        \subsubsection{Skrypty}

            Do przeprowadzenia eksperymentów zostały wykorzystane opracowane skrypty w języku \texttt{bash}. Każdy skrypt uruchamia klasyfikację taksonomiczną dla podzbiorów z wykorzystaniem jednej metody. Uruchomienie wszystkich skryptów pozwala na zebranie danych dla obu eksperymentów.

            \todo{
                Uruchomienie skryptów?
                Przykład skryptu?
            }
            
            Do przetworzenia wyników oraz wygenerowania wykresów wykorzystano skrypty stworzone w języku \texttt{Python}.

            \todo{
                Uruchomienie skryptu?
                Przykład skryptu?
            }

    % ===== ===== ===== =====
    % WYNIKI
    % ===== ===== ===== =====
    \subsection{Wyniki}

        \todo{
            \begin{enumerate}
                \item {opis przeprowadzonych eksperymentów}
            \end{enumerate}
        }

        \subsubsection{Eksperyment 1: czas wykonania klasyfikacji taksonomicznej}

            \todo{
                \begin{enumerate}
                    \item {cel,}
                    \item {założenia,}
                    \item {wyniki,}
                    \item {wykres/tabela,}
                    \item {interpretacja}
                \end{enumerate}
            }

        \subsubsection{Eksperyment 2: jakość klasyfikacjia taksonomicznej}

            \todo{
                \begin{enumerate}
                    \item {cel,}
                    \item {założenia,}
                    \item {wyniki,}
                    \item {wykres/tabela,}
                    \item {interpretacja}
                \end{enumerate}
            }

        \subsubsection{Analiza wyników}

            \todo{
                \begin{enumerate}
                    \item {porównanie osiągniętych wyników z oczekiwaniami,}
                    \item {dyskusja nad błędami i ich wpływem na eksperymenty}
                \end{enumerate}
            }


% \clearpage
%     \section{Eksperymenty}

%         Przeprowadzono eksperymenty jakościowe oraz wydajnościowe dla trzech metod oraz dodatkowo dla klasyfikacji taksonomicznej.

%         \subsection{Zbiory danych}
%             Do przeprowadzenia eksperymentów wykorzystano zbiór \textit{CAMI II Toy Human Microbiome Project}, z którego wylosowano zbiór 2047 sekwencji genetycznych, które nie były wykorzystane w procesie uczenia sieci neuronowej. Zbiór następnie został podzielony na podzbiory o wielkościach $n^k$ dla $k \in [0, 10]$.

%         \subsection{Miara jakości}
%             Do oceny jakości wyników pełnej klasyfikacji taksonomicznej został wykorzystany zmodyfikowany indeks Jaccarda, wyrażony wzorem:

%             \begin{equation}
%                 \text{Miara jakosci} = \frac{1}{|| R \cup E||} \sum_{o \in (R \cup E)}{
%                     \frac{\min{(R_o, E_o)}}{\max{(R_o, E_o)}}
%                 }
%             \end{equation}
    
%             gdzie 
%             \begin{align*}
%                 R, E &- \text{zbiory organizmów referencyjnych i otrzymanych}, \\
%                 E_o, R_o &- \text{jakość organizmów w zbiorach } E \text{ i } R.
%             \end{align*}

%             Wykorzystano również dodatkowe miary jakości, które oceniają tworzone klastry w wyniku wykorzystania różnych metod określania niepodobieństwa. Pierwszą z nich jest znormalizowana informacja wzajemna (ang. \text{Normalized mutual information, NMI}) i służy do oceny klastrów, drugą jest czułość wykorzystywaną do oceny reprezentantów (ang. \textit{sensitivity}). Miary zdefiniowane są jako:

%             \begin{equation}
%                 sensitivity = \frac{\text{liczba wyników prawdziwie dodatnych}}{
%                     \text{liczba wyników prawdziwie dodatnych} + \text{liczba wyników fałszywie ujemnych}
%                 }
%             \end{equation}
            
%             \begin{equation}
%                 NMI = \frac{I(X; Y)}{\sqrt{H(X) \cdot H(Y)}}
%             \end{equation}

%             gdzie 
%             \begin{align*}
%                 I(X; Y) &= \sum_{y \in Y}{ \sum_{x \in X}{p(x, y) \log_{2}{\frac{p(x, y)}{p(x) p(y)}}}}, \\
%                 H(X) &= - \sum_{x \in X}{ p(x) \log_{2}{p(x)}}, \\
%                 I(X; Y) &- \text{informacja wzajemna między zbiorami $X$ oraz $Y$}, \\
%                 H(X) &- \text{entropia zbioru $X$}, \\
%                 H(Y) &- \text{entropia zbioru $Y$}, \\
%                 p(x) &- \text{prawdopobieństwo zajścia zdarzenia $x$}, \\
%                 p(x, y) &- \text{wspólny rozkład prawdopodobieństwa $X$ oraz $Y$ }.
%             \end{align*}

%         \subsection{Procedura}

%             % \subsubsection{Wykorzystany sprzęt}
%             % Eksperymenty zostały przeprowadzone na serwerze wyposażonym w procesor Intel Core i7-6850KK (4 vCPU), 40GB pamięci RAM oraz kartę graficzną GTX 1080TI.

%             % \subsubsection{Uruchomienie}
%            Eksperymenty zostały przeprowadzone przy wykorzystaniu zbudowanego narzędzia, które monitorowało wykorzystanie procesora oraz pamięci przez eksperyment. Maksymalny czas eksperymentu ustawiono na 4 godziny. Liczbę grup ustawiono na $\sqrt{n}$, gdzie $n$ to liczba sekwencji w danym eksperymencie.

% \begin{enumerate}
%     \item Badania jakościowe
%     \begin{itemize}
%         \item opis bazy / referencji
%         \item miara jakości
%         \item 2-3 eksperymenty
%     \end{itemize}
%     \item Badania wydajnościowe
%     \begin{itemize}
%         \item pamięć, CPU
%         \item 2-3 eksperymenty  (w zależności od parametrów)
%     \end{itemize}
%     \item Wnioski
% \end{enumerate}